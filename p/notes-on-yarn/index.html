<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><link rel=dns-prefetch href=https://fonts.googleapis.com><link rel=dns-prefetch href=https://cdn.jsdelivr.net><link rel=dns-prefetch href=https://scripts.simpleanalyticscdn.com><link rel=preconnect href=https://fonts.googleapis.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=preconnect href=https://scripts.simpleanalyticscdn.com crossorigin><meta http-equiv=x-dns-prefetch-control content="on"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5,minimum-scale=1"><meta name=format-detection content="telephone=no"><meta name=theme-color content="#4e54c8" media="(prefers-color-scheme: light)"><meta name=theme-color content="#1a1a2e" media="(prefers-color-scheme: dark)"><link rel=apple-touch-icon href><meta name=description content="YaRN (Yet Another RoPE extentionN method) 时23年9月EleutherAI等提出来的一个扩展LLM上下文长度的方法，后来被Qwen系列模型所应用。"><meta name=keywords content><meta name=author content="Mao Song"><link rel=canonical href=https://maosong.website/p/notes-on-yarn/><meta property="og:title" content="Notes on YaRN"><meta property="og:description" content="YaRN (Yet Another RoPE extentionN method) 时23年9月EleutherAI等提出来的一个扩展LLM上下文长度的方法，后来被Qwen系列模型所应用。"><meta property="og:type" content="article"><meta property="og:url" content="https://maosong.website/p/notes-on-yarn/"><meta property="og:site_name" content="Mao Song(毛松)'s Homepage"><meta property="og:locale" content="en"><meta property="og:image" content="https://maosong.website/p/notes-on-yarn/YaRN_comparison_RoPE_PI.png"><meta property="og:image:alt" content="Notes on YaRN"><meta property="article:published_time" content="2025-07-03T14:40:49+08:00"><meta property="article:modified_time" content="2025-08-13T16:34:14+08:00"><meta property="article:author" content="Mao Song"><meta property="article:tag" content="Qwen"><meta property="article:tag" content="Context"><meta property="article:tag" content="position encoding"><meta name=robots content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"><meta name=googlebot content="index, follow"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Notes on YaRN","description":"YaRN (Yet Another RoPE extentionN method) 时23年9月EleutherAI等提出来的一个扩展LLM上下文长度的方法，后来被Qwen系列模型所应用。","author":{"@type":"Person","name":"Mao Song"},"datePublished":"2025-07-03T14:40:49\u002b08:00","dateModified":"2025-08-13T16:34:14\u002b08:00","image":"https:\/\/maosong.website\/p\/notes-on-yarn\/YaRN_comparison_RoPE_PI.png","publisher":{"@type":"Organization","name":"Mao Song(毛松)\u0027s Homepage","logo":{"@type":"ImageObject","url":"https:\/\/maosong.website\/"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maosong.website\/p\/notes-on-yarn\/"},"keywords":"Qwen, Context, position encoding","articleSection":"post","inLanguage":"en"}</script><title>Notes on YaRN</title>
<link rel=stylesheet href=/scss/style.min.fb2ef3860c8335f835ed6d55e46d9c435d7a37375d695eed32deb59ecfadc82b.css><script async src=https://scripts.simpleanalyticscdn.com/latest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><a href=#main-content class=skip-to-main>Skip to main content</a><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu9788782091159651930.jpg width=300 height=240 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Mao Song(毛松)'s Homepage</a></h1><h2 class=site-description>Delving into the Latent Unknown.</h2></div></header><ol class=menu-social><li><a href=https://b23.tv/a0Bb9Z1 target=_blank title=bilibili rel=me><svg role="img" viewBox="0 0 24 24"><title>Bilibili</title><path d="M17.813 4.653h.854c1.51.054 2.769.578 3.773 1.574 1.004.995 1.524 2.249 1.56 3.76v7.36c-.036 1.51-.556 2.769-1.56 3.773s-2.262 1.524-3.773 1.56H5.333c-1.51-.036-2.769-.556-3.773-1.56S.036 18.858.0 17.347v-7.36c.036-1.511.556-2.765 1.56-3.76 1.004-.996 2.262-1.52 3.773-1.574h.774l-1.174-1.12a1.234 1.234.0 01-.373-.906c0-.356.124-.658.373-.907l.027-.027c.267-.249.573-.373.92-.373s.653.124.92.373L9.653 4.44c.071.071.134.142.187.213h4.267a.836.836.0 01.16-.213l2.853-2.747c.267-.249.573-.373.92-.373s.662.151.929.4.391.551.391.907c0 .355-.124.657-.373.906zM5.333 7.24c-.746.018-1.373.276-1.88.773-.506.498-.769 1.13-.786 1.894v7.52c.017.764.28 1.395.786 1.893.507.498 1.134.756 1.88.773h13.334c.746-.017 1.373-.275 1.88-.773.506-.498.769-1.129.786-1.893v-7.52c-.017-.765-.28-1.396-.786-1.894-.507-.497-1.134-.755-1.88-.773zM8 11.107c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c0-.373.129-.689.386-.947.258-.257.574-.386.947-.386zm8 0c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c.017-.391.15-.711.4-.96.249-.249.56-.373.933-.373z"/></svg></a></li><li><a href=https://github.com/MaoSong2022 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href='https://scholar.google.com/citations?user=BaqGkQQAAAAJ' target=_blank title="Google Scholar" rel=me><svg role="img" viewBox="0 0 24 24"><title>Google Scholar</title><path d="M5.242 13.769.0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977.0-5.548 1.748-6.758 4.269zM12 10a7 7 0 100 14 7 7 0 000-14z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a></li><li><a href=#preliminary>Preliminary</a></li><li><a href=#unified-perspective-on-related-work>Unified Perspective on Related Work</a><ol><li><a href=#position-interpolation>Position Interpolation</a></li><li><a href=#ntk-aware-interpolation>NTK-aware Interpolation</a></li><li><a href=#ntk-by-parts-interpolation>NTK-by-parts Interpolation</a></li><li><a href=#dynamic-ntk-interpolation>Dynamic NTK Interpolation</a></li></ol></li><li><a href=#yarn>YaRN</a></li><li><a href=#evaluation>Evaluation</a></li><li><a href=#code>Code</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main id=main-content class="main full-width" role=main aria-label="Main content"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/llm/>LLM</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/notes-on-yarn/>Notes on YaRN</a></h2><h3 class=article-subtitle>YaRN (Yet Another RoPE extentionN method) 时23年9月EleutherAI等提出来的一个扩展LLM上下文长度的方法，后来被Qwen系列模型所应用。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>July 3, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>7 minute read</time></div></footer></div></header><section class=article-content><h2 id=introduction><a href=#introduction class=header-anchor></a>Introduction</h2><p>YaRN (Yet Another RoPE extentionN method) 时23年9月EleutherAI等提出来的一个扩展LLM上下文长度的方法，后来被Qwen系列模型所应用。</p><h2 id=preliminary><a href=#preliminary class=header-anchor></a>Preliminary</h2><p>作者首先回顾了一下RoPE, 具体内容请参见上一篇<a class=link href=https://maosong.website/p/notes-on-position-encoding/ target=_blank rel=noopener>blog</a>。并使用了 $f_{W}(x_m, m, \theta_d)$ 来表示RoPE：</p>$$
f_{W}(x_m, m, \theta_{d}) = \Theta_{\theta, m}^d W x_m
$$<p>其中 $\Theta_{\theta, m}^d\in\mathbb{R}^{d\times d}$ 是多维旋转矩阵, $\theta_d=[\theta_{0,d},\dots,\theta_{(d-2)/2,d}]\in\mathbb{R}^{d/2}$, $\theta_{i,d}=\theta^{2i/d}$, $\theta>0$ 是一个超参数，RoPE中设置为 $\theta=10000$, $W\in\{W_q,W_k\}\subset\mathbb{R}^{d\times d}$ 是对应的query/key projection layer的权重矩阵， $x\in\mathbb{R}^{d}$ 是输入的hidden states.</p><p>接下来，作者定义了两个新的变量：</p><p><strong>scaling factor</strong>
假设预训练的上下文长度为 $L$, 扩展的上下文长度为 $L'>L$, 则我们定义scaling factor 为</p>$$
s = \frac{L'}{L}
$$<p>易知 $s>1$.</p><p><strong>wavelength</strong>
我们将 $\lambda_d$ 定义为 $i$-th 维的RoPE embedding对应的 wavelength：</p>$$
\lambda_{i,d} = \frac{2\pi}{\theta_{i,d}} = 2\pi\theta^{2i/d}, \ i=0,\dots,(d-2)/2
$$<p>wavelength描述了对于第$i$ 个维度，RoPE旋转一周 ($2\pi$) 所需要的上下文长度。</p><h2 id=unified-perspective-on-related-work><a href=#unified-perspective-on-related-work class=header-anchor></a>Unified Perspective on Related Work</h2><p>基于 $f_{W}(x_m, m, \theta_d)$, 作者统一了已有的扩展上下文长度的方法，作者将不同的扩展方法使用一个通用函数 $f_W(x_m,g(m), h(\theta_d))$ 来表示，这里 $g(m)$ 和 $h(\theta_d)$ 分别代表了不同的长度外推方法所使用的变换。</p><h3 id=position-interpolation><a href=#position-interpolation class=header-anchor></a>Position Interpolation</h3><p>Position Interpolation (PI) 的核心思想在于，我们可以通过Interpolation，将超过预训练长度的文本给压缩到当前最大长度，以此来避免RoPE外推产生的问题，其对应的公式为</p>$$
f'_W(x_m,m,\theta_d) = f_W(x_m, \frac{mL}{L'}, \theta_d)
$$<p>其中 $L'>L$ 为我们扩展之后的上下文长度， $L$ 为我们预训练的上下文长度。使用通用函数表示的话，我们有</p>$$
g(m) = \frac{m}{s},\quad h(\theta_d) = \theta_d
$$<h3 id=ntk-aware-interpolation><a href=#ntk-aware-interpolation class=header-anchor></a>NTK-aware Interpolation</h3><p>PI的问题是，并没有考虑不同维度的wavelength。
基于NTK理论，DNN当输入维度比较低，且embedding缺少高频内容时，模型就会很难学习到高频信息。对应到RoPE里面，输入的token position id是低位信息（1维），而输出的RoPE是一个 $d$ 维的复杂向量。因此，当输入token非常相似却距离非常近时，RoPE就会丢失高频的细节信息</p><p>因此，为了解决这个问题，作者对不同的维度使用了不同的缩放策略：<strong>维度比较小时，其缩放的更多，维度比较大是，其缩放的更少。</strong></p><p>基于这个策略，作者提出了NTK-aware interpolation，其定义如下：</p>$$
g(m) = m, \quad h(\theta_{i,d}) = \theta'^{-2i/d}, i=0,\dots,(d-2)/2
$$<p>其中</p>$$
\theta' = \theta\cdot s^{\frac{d}{d-2}}
$$<p>实际中，这种方法会产生out-of-bound的值，因此最终结果会比PI要差一点，为了解决这个问题，一般会使用比 $s$ 更大的scaling factor.</p><blockquote><p>上式的推导基于一个简单的假设：我们希望最后一个维度的wavelength在scaling之后，是线性变化的，即 $\theta'_{(d-2)/2,d}=s\theta_{(d-2)/2,d}$, 求解之后，我们就得到了上面的定义</p></blockquote><p>PI 和NTK-aware interpolation的问题在于，我们对不同的维度的处理都是一样的。这类不在乎wavelength的方法被称为<strong>blind interpolation methods</strong>, 接下来要介绍的就是基于wavelength的方法，即<strong>target interpolation methods</strong>.</p><h3 id=ntk-by-parts-interpolation><a href=#ntk-by-parts-interpolation class=header-anchor></a>NTK-by-parts Interpolation</h3><p>与NTK-aware interpolation， NTK-by-parts interpolation基于wavelength来考虑不同维度上所做的变换。</p><p>对于低维度，其 $\theta_{i,d}$ 非常大，因此旋转一周所需要的上下文长度也非常大。实际上就导致某些维度的embedding并不是均匀分布的，（比如说只有 $0\sim\pi$ 这个区间的embedding），这个时候，模型就只能访问到绝对位置信息，而访问不到相对位置信息。
另外，当我们对所有的维度都进行scale的时候，所有的token都会与彼此更加靠近，这损害了模型对于局部信息的获取能力。
基于这些认知，作者基于wavelength，对不同的维度分别进行处理：</p><ol><li>如果wavelength远小于上下文长度 $L$， 则我们不做任何处理</li><li>如果wavelength等于或者大于上下文长度 $L$， 则我们使用NTK-aware interpolation 进行处理</li><li>对于中间的其他维度，我们进行了一个trade off</li></ol><p>作者定义了一个ratio $r$ 来描述原始上下文长度 $L$ 和 wavelength 之间的关系</p>$$
r(i,d) = \frac{L}{\lambda_{i,d}} = \frac{L}{2\pi\theta'^{2i/d}}
$$<p>基于这个ratio，我们可以定义上面的三种处理方式对应的权重</p>$$
\gamma(r) = \begin{cases}
0, &\text{if } r < \alpha\\
1, &\text{if } r > \beta\\
\frac{r-\alpha}{\beta-\alpha}, &\text{otherwise}
\end{cases}
$$<p>其中， $\beta>\alpha>0$ 是超参数， $r<\alpha$, $r<\beta$ 分别代表了上面的第1种，第2种情况。</p><p>最后，NTK-by-parts interpolation的定义如下</p>$$
g(m) = m, \quad h(\theta_i) = \left(1-\gamma(r(i,d)\right)\frac{\theta_i}{s} + \gamma(r(i,d))\theta_i
$$<p>作者通过实验发现，在LLaMA上，$\alpha=1$ 和 $\beta=32$ 是一个比较好的选择</p><h3 id=dynamic-ntk-interpolation><a href=#dynamic-ntk-interpolation class=header-anchor></a>Dynamic NTK Interpolation</h3><p>在实际中，一个经常遇到的场景就是sequence length会从1逐步上升到最大上下文长度，比如说inference的时候。对于这种情况，我们有两种解决方法：</p><ol><li>在整个inference周期中，RoPE的scaling factor都设置为 $s=K'/L$, 其中$L'$ 是扩展后的上下文长度</li><li>在每次foward的过程汇总，都更新sclaing factor $s=\max(1, \ell'/L)$, 这里 $\ell'$ 是当前sequence的长度</li></ol><p>作者发现，方案1在sequence长度小于 $L$的时候性能会下降，并且当上下文长度超过 $L'$ 时，性能下降的更快。
但是，方案2可以让模型的性能下降曲线更平缓。因此，作者将这种inference-time方法称为 <strong>Dynamic Scaling method</strong>, 当其与NTK-aware方法结合时，就得到了 <strong>Dynamic NTK interpolation</strong></p><p>作者通过实验发现，Dynamic NTK interpolation在$L'=L$ 时，效果非常好</p><h2 id=yarn><a href=#yarn class=header-anchor></a>YaRN</h2><p>在YaRN中，作者针对Dynamic NTK interpolation做了进一步改进，也就是在计算attention softmax时，加入了一个温度参数 $t>0$, 这样attention的计算就变成了</p>$$
\mathrm{Attn}(Q, K, V) = \mathrm{softmax}\left(\frac{QK^T}{t\sqrt{d}}\right)V
$$<p>作者发现，通过这种scaling的方式，YaRN可以在不改变代码的前提下，更改attention的机制。并且，其不增加训练和推理的cost</p><p>作者将YaRN定义为<strong>结合了NTK-by-parts interpolation和上述scaling技巧的方法</strong></p><p>对于LLaMA，作者推荐使用如下参数：</p>$$
\sqrt{\frac{1}{t}} = 0.1\ln(s) + 1.
$$<p>实验结果如下</p><p><img src=/p/notes-on-yarn/YaRN_temperature_ablation.png width=1049 height=528 loading=lazy alt="Ablation study on temperature" class=gallery-image data-flex-grow=198 data-flex-basis=476px></p><p>作者发现：</p><ol><li>对于合适的 $t$, 扩展上下文之后，perplexity会变的更好</li><li>最好的$t$ 对于不同的位置和样本提升都是一样的</li></ol><h2 id=evaluation><a href=#evaluation class=header-anchor></a>Evaluation</h2><p>实验结果如下</p><div class=table-wrapper><table><thead><tr><th>Extension Method</th><th>Trained Tokens</th><th>Context Window</th><th></th><th></th><th></th><th>Evaluation Context Window Size</th><th></th><th></th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td>2048</td><td>4096</td><td>6144</td><td>8192</td><td>10240</td></tr><tr><td>PI (s = 2)</td><td>1B</td><td>8k</td><td></td><td>3.92</td><td>3.51</td><td>3.51</td><td>3.34</td><td>8.07</td></tr><tr><td>NTK ($\theta$ = 20k)</td><td>1B</td><td>8k</td><td></td><td>4.20</td><td>3.75</td><td>3.74</td><td>3.59</td><td>6.24</td></tr><tr><td>YaRN (s = 2)</td><td>400M</td><td>8k</td><td></td><td><strong>3.91</strong></td><td><strong>3.50</strong></td><td><strong>3.51</strong></td><td>3.35</td><td><strong>6.04</strong></td></tr></tbody></table></div><p>可以看到，YaRN使用的数据更少，并且当模型扩展到10240的时候，其表现下降的最慢，这说明了YaRN在扩展上下文长度时的有效性</p><p>原始RoPE，dynamic-PI和dynamic-YaRN的对比</p><p><img src=/p/notes-on-yarn/YaRN_comparison_RoPE_PI.png width=1154 height=573 loading=lazy alt="Comparison with RoPE and PI" class=gallery-image data-flex-grow=201 data-flex-basis=483px></p><p>可以看到，RoPE的上下文扩展能力很差，Dynamic-YaRN的表现最好。</p><h2 id=code><a href=#code class=header-anchor></a>Code</h2><p>YaRN的实现在<a class=link href=https://github.com/huggingface/transformers/blob/main/src/transformers/modeling_rope_utils.py target=_blank rel=noopener>HuggingFace/src/transformers/modeling_rope_utils.py</a> 里的 <code>_compute_yarn_parameters</code> 函数里，其返回 <code>inv_freq</code> 以及 <code>attention_factor</code> 两个量，前者代表了 $\theta_d$, 后者代表 $t\sqrt{d}$.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_mscale</span><span class=p>(</span><span class=n>scale</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>scale</span> <span class=o>&lt;=</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mf>1.0</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mf>0.1</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>scale</span><span class=p>)</span> <span class=o>+</span> <span class=mf>1.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>find_correction_dim</span><span class=p>(</span><span class=n>num_rotations</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>base</span><span class=p>,</span> <span class=n>max_position_embeddings</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Inverse dimension formula to find the dimension based on the number of rotations&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>dim</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>max_position_embeddings</span> <span class=o>/</span> <span class=p>(</span><span class=n>num_rotations</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>pi</span><span class=p>)))</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>base</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>find_correction_range</span><span class=p>(</span><span class=n>low_rot</span><span class=p>,</span> <span class=n>high_rot</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>base</span><span class=p>,</span> <span class=n>max_position_embeddings</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Find dimension range bounds based on rotations&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>low</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>floor</span><span class=p>(</span><span class=n>find_correction_dim</span><span class=p>(</span><span class=n>low_rot</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>base</span><span class=p>,</span> <span class=n>max_position_embeddings</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>high</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>find_correction_dim</span><span class=p>(</span><span class=n>high_rot</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>base</span><span class=p>,</span> <span class=n>max_position_embeddings</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=n>low</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=nb>min</span><span class=p>(</span><span class=n>high</span><span class=p>,</span> <span class=n>dim</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>linear_ramp_factor</span><span class=p>(</span><span class=nb>min</span><span class=p>,</span> <span class=nb>max</span><span class=p>,</span> <span class=n>dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>min</span> <span class=o>==</span> <span class=nb>max</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>max</span> <span class=o>+=</span> <span class=mf>0.001</span>  <span class=c1># Prevent singularity</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>linear_func</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>dim</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span> <span class=o>-</span> <span class=nb>min</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=nb>max</span> <span class=o>-</span> <span class=nb>min</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ramp_func</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=n>linear_func</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ramp_func</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>YaRNRotaryEmbedding</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>beta_fast</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;beta_fast&#34;</span><span class=p>)</span> <span class=ow>or</span> <span class=mi>32</span>
</span></span><span class=line><span class=cl>        <span class=n>beta_slow</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;beta_slow&#34;</span><span class=p>)</span> <span class=ow>or</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>dim</span> <span class=o>=</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;head_dim&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>factor</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>max_position_embeddings</span> <span class=o>/</span> <span class=n>original_max_position_embeddings</span>
</span></span><span class=line><span class=cl>        <span class=n>pos_freqs</span> <span class=o>=</span> <span class=n>base</span> <span class=o>**</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>inv_freq_extrapolation</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=n>pos_freqs</span>
</span></span><span class=line><span class=cl>        <span class=n>inv_freq_interpolation</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=n>factor</span> <span class=o>*</span> <span class=n>pos_freqs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>low</span><span class=p>,</span> <span class=n>high</span> <span class=o>=</span> <span class=n>find_correction_range</span><span class=p>(</span><span class=n>beta_fast</span><span class=p>,</span> <span class=n>beta_slow</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>base</span><span class=p>,</span> <span class=n>original_max_position_embeddings</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Get n-dimensional rotational scaling corrected for extrapolation</span>
</span></span><span class=line><span class=cl>        <span class=n>inv_freq_extrapolation_factor</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>linear_ramp_factor</span><span class=p>(</span><span class=n>low</span><span class=p>,</span> <span class=n>high</span><span class=p>,</span> <span class=n>dim</span> <span class=o>//</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>inv_freq</span> <span class=o>=</span> <span class=p>(</span><span class=n>inv_freq_interpolation</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>inv_freq_extrapolation_factor</span><span class=p>)</span> <span class=o>+</span> <span class=n>inv_freq_extrapolation</span> <span class=o>*</span> <span class=n>inv_freq_extrapolation_factor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>attention_factor</span> <span class=o>=</span> <span class=n>get_mscale</span><span class=p>(</span><span class=n>factor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>position_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>cos</span><span class=p>,</span> <span class=n>sin</span>
</span></span></code></pre></td></tr></table></div></div><p>实际的transformers代码中，Qwen使用的还是默认的RoPE，在inference时如果我们需要扩展上下文，可以通过修改config的形式：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>pipeline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_name_or_path</span> <span class=o>=</span> <span class=s2>&#34;Qwen/Qwen3-8B&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generator</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;text-generation&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>model_name_or_path</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_kwargs</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max_position_embeddings&#34;</span><span class=p>:</span> <span class=mi>131072</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rope_scaling&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;rope_type&#34;</span><span class=p>:</span> <span class=s2>&#34;yarn&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;factor&#34;</span><span class=p>:</span> <span class=mf>4.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;original_max_position_embeddings&#34;</span><span class=p>:</span> <span class=mi>32768</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=conclusion><a href=#conclusion class=header-anchor></a>Conclusion</h2><p>在本文中，作者首先构建了一个统一的表征不同上下文长度扩展的形式，接下来作者分析了不同上下文长度扩展的不足，并提出了YaRN这种上下文长度扩展方式，结果发现，YaRN不仅在短上下文长度下面表现很好，当上下文长度扩展之后，其表现依然非常优秀。</p><h2 id=references><a href=#references class=header-anchor></a>References</h2><ul><li><a class=link href=http://arxiv.org/abs/2309.00071 target=_blank rel=noopener>arxiv YaRN</a></li><li><a class=link href=https://arxiv.org/pdf/2306.15595 target=_blank rel=noopener>arxiv PI</a></li><li><a class=link href=https://qwen.readthedocs.io/en/latest/inference/transformers.html#enabling-long-context target=_blank rel=noopener>Qwen documentation</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/qwen/>Qwen</a>
<a href=/tags/context/>Context</a>
<a href=/tags/position-encoding/>Position Encoding</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on August 13, 2025 at 4:34 PM</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/dual-chunk-attention/><div class=article-details><h2 class=article-title>Dual Chunk Attention</h2></div></a></article><article><a href=/p/notes-on-qwen3-next/><div class=article-details><h2 class=article-title>Notes on Qwen3-Next</h2></div></a></article><article><a href=/p/notes-on-gated-attention/><div class=article-details><h2 class=article-title>Notes on Gated Attention</h2></div></a></article><article><a href=/p/notes-on-nope/><div class=article-details><h2 class=article-title>Notes on NoPE</h2></div></a></article><article><a href=/p/notes-on-alibi/><div class=article-details><h2 class=article-title>Notes on ALiBi</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=MaoSong2022/MaoSong2022.github.io issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Mao Song(毛松)'s Homepage</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>