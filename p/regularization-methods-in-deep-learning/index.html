<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><link rel=dns-prefetch href=https://fonts.googleapis.com><link rel=dns-prefetch href=https://cdn.jsdelivr.net><link rel=dns-prefetch href=https://scripts.simpleanalyticscdn.com><link rel=preconnect href=https://fonts.googleapis.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=preconnect href=https://scripts.simpleanalyticscdn.com crossorigin><meta http-equiv=x-dns-prefetch-control content="on"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5,minimum-scale=1"><meta name=format-detection content="telephone=no"><meta name=theme-color content="#4e54c8" media="(prefers-color-scheme: light)"><meta name=theme-color content="#1a1a2e" media="(prefers-color-scheme: dark)"><link rel=apple-touch-icon href><meta name=description content="Overview of the regularization methods in deep learning."><meta name=keywords content><meta name=author content="Mao Song"><link rel=canonical href=https://maosong.website/p/regularization-methods-in-deep-learning/><meta property="og:title" content="Regularization methods in deep learning"><meta property="og:description" content="Overview of the regularization methods in deep learning."><meta property="og:type" content="article"><meta property="og:url" content="https://maosong.website/p/regularization-methods-in-deep-learning/"><meta property="og:site_name" content="Mao Song(毛松)'s Homepage"><meta property="og:locale" content="en"><meta property="og:image" content="https://maosong.website/p/regularization-methods-in-deep-learning/regularization_overview.png"><meta property="og:image:alt" content="Regularization methods in deep learning"><meta property="article:published_time" content="2024-04-27T18:02:02+08:00"><meta property="article:modified_time" content="2025-02-26T11:50:53+08:00"><meta property="article:author" content="Mao Song"><meta property="article:tag" content="regularization"><meta name=robots content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"><meta name=googlebot content="index, follow"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Regularization methods in deep learning","description":"Overview of the regularization methods in deep learning.","author":{"@type":"Person","name":"Mao Song"},"datePublished":"2024-04-27T18:02:02\u002b08:00","dateModified":"2025-02-26T11:50:53\u002b08:00","image":"https:\/\/maosong.website\/p\/regularization-methods-in-deep-learning\/regularization_overview.png","publisher":{"@type":"Organization","name":"Mao Song(毛松)\u0027s Homepage","logo":{"@type":"ImageObject","url":"https:\/\/maosong.website\/"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maosong.website\/p\/regularization-methods-in-deep-learning\/"},"keywords":"regularization","articleSection":"post","inLanguage":"en"}</script><title>Regularization methods in deep learning</title>
<link rel=stylesheet href=/scss/style.min.fb2ef3860c8335f835ed6d55e46d9c435d7a37375d695eed32deb59ecfadc82b.css><script async src=https://scripts.simpleanalyticscdn.com/latest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><a href=#main-content class=skip-to-main>Skip to main content</a><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu9788782091159651930.jpg width=300 height=240 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Mao Song(毛松)'s Homepage</a></h1><h2 class=site-description>Delving into the Latent Unknown.</h2></div></header><ol class=menu-social><li><a href=https://b23.tv/a0Bb9Z1 target=_blank title=bilibili rel=me><svg role="img" viewBox="0 0 24 24"><title>Bilibili</title><path d="M17.813 4.653h.854c1.51.054 2.769.578 3.773 1.574 1.004.995 1.524 2.249 1.56 3.76v7.36c-.036 1.51-.556 2.769-1.56 3.773s-2.262 1.524-3.773 1.56H5.333c-1.51-.036-2.769-.556-3.773-1.56S.036 18.858.0 17.347v-7.36c.036-1.511.556-2.765 1.56-3.76 1.004-.996 2.262-1.52 3.773-1.574h.774l-1.174-1.12a1.234 1.234.0 01-.373-.906c0-.356.124-.658.373-.907l.027-.027c.267-.249.573-.373.92-.373s.653.124.92.373L9.653 4.44c.071.071.134.142.187.213h4.267a.836.836.0 01.16-.213l2.853-2.747c.267-.249.573-.373.92-.373s.662.151.929.4.391.551.391.907c0 .355-.124.657-.373.906zM5.333 7.24c-.746.018-1.373.276-1.88.773-.506.498-.769 1.13-.786 1.894v7.52c.017.764.28 1.395.786 1.893.507.498 1.134.756 1.88.773h13.334c.746-.017 1.373-.275 1.88-.773.506-.498.769-1.129.786-1.893v-7.52c-.017-.765-.28-1.396-.786-1.894-.507-.497-1.134-.755-1.88-.773zM8 11.107c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c0-.373.129-.689.386-.947.258-.257.574-.386.947-.386zm8 0c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c.017-.391.15-.711.4-.96.249-.249.56-.373.933-.373z"/></svg></a></li><li><a href=https://github.com/MaoSong2022 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href='https://scholar.google.com/citations?user=BaqGkQQAAAAJ' target=_blank title="Google Scholar" rel=me><svg role="img" viewBox="0 0 24 24"><title>Google Scholar</title><path d="M5.242 13.769.0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977.0-5.548 1.748-6.758 4.269zM12 10a7 7 0 100 14 7 7 0 000-14z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#implicit-regularization-in-gradient-descent>Implicit Regularization in gradient descent</a></li><li><a href=#implicit-regularization-in-stochastic-gradient-descent>Implicit Regularization in stochastic gradient descent</a></li></ol><ol><li><a href=#early-stopping>Early stopping</a></li><li><a href=#ensembling>Ensembling</a></li><li><a href=#dropout>Dropout</a></li><li><a href=#applying-noise>Applying noise</a></li><li><a href=#bayesian-inference>Bayesian inference</a></li><li><a href=#transfer-learning-and-multi-task-learning>Transfer learning and multi-task learning</a></li><li><a href=#self-supervised-learning>Self-supervised learning</a></li><li><a href=#augmentation>Augmentation</a></li></ol></nav></div></section></aside><main id=main-content class="main full-width" role=main aria-label="Main content"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/deep-learning/>Deep Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/regularization-methods-in-deep-learning/>Regularization methods in deep learning</a></h2><h3 class=article-subtitle>Overview of the regularization methods in deep learning.</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>April 27, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>6 minute read</time></div></footer></div></header><section class=article-content><p>To reduce the gap of the performance of the model on the training dataset and the test dataset, we need use regularization methods.</p><h1 id=introduction><a href=#introduction class=header-anchor></a>Introduction</h1><p>Possible reasons for the discrepancy that the model performs worse on the test dataset than on the training dataset are:</p><ol><li>the model describes statistical peculiarities of the training dataset that are not representative of the true mapping from the input to the output, that is, overfitting.</li><li>the model is unconstrained in areas with no training areas, leading to suboptimal predictions</li></ol><h1 id=explicit-regularization-methods><a href=#explicit-regularization-methods class=header-anchor></a>Explicit Regularization Methods</h1><p>Consider fitting a model $f(\bm{x}; \phi)$ with parameter $\phi$ using a training dataset $\{\bm{x}_i,y_i\}$, we seek to minimize the loss function $L(\phi)$:</p>$$ \hat{\phi} = \arg\min_{\phi}L(\phi;\{\bm{x}_i,y_i\}) $$<p>Now, to bias the minimization towards certain solutions, we add an additional term:</p>$$ \hat{\phi} = \arg\min_{\phi}[L(\phi;\{\bm{x}_i,y_i\}) + \lambda g(\phi)] $$<p>where $g(\phi)$ is called the regularization term and $\lambda>0$ is a hyperparameter.</p><p>In the probabilistic perspective, we can construct the loss function from <em>maximum likelihood estimation</em>, or MLE, that is</p>$$ \hat{\phi} = \arg\max_{\phi}\left[ \prod_{i}\mathrm{Pr}(y_i\mid \bm{x}_i,\phi) \right] $$<p>The regularization term can be considered as a <em>prior</em> $\mathrm{Pr}(\phi)$， in this way, we are now using <em>maximum a posteriori</em> criterion:</p>$$ \hat{\phi} = \arg\max_{\phi}\left[ \prod_{i}\mathrm{Pr}(y_i\mid \bm{x}_i,\phi)\mathrm{Pr}(\phi) \right] $$<h1 id=implicit-regularization-methods><a href=#implicit-regularization-methods class=header-anchor></a>Implicit Regularization Methods</h1><p>Gradient descent and stochastic gradient descent are commonly used to minimize the loss functions, however, neither of them moves neutrally to the minimum of the loss function, thus the implicit regularization method is proposed to solve the problem.</p><h2 id=implicit-regularization-in-gradient-descent><a href=#implicit-regularization-in-gradient-descent class=header-anchor></a>Implicit Regularization in gradient descent</h2><p>The change of the parameters $\phi$ is defined by the differential equation:</p>$$ \frac{d{\phi}}{d t} = -\frac{dL}{d\phi} $$<p>gradient descent uses <a class=link href=https://en.wikipedia.org/wiki/Difference_quotient target=_blank rel=noopener>difference quotient</a> with increment (or learning rate) $\alpha$ to approximate the change of $\phi$:</p>$$ \frac{\phi_{t+1}-\phi_{t}}{\alpha}=-\frac{dL}{d\phi} \Rightarrow \phi_{t+1} = \phi_{t} - \alpha\frac{dL}{d\phi} $$<p>However, this discretization causes deviation from the continuous path.</p><p>To fix the problem, and extra item is added to the loss to avoid the deviation caused by discretization:</p>$$ \tilde{L}(\phi) = L(\phi) + \frac{\alpha}{4}\left\Vert \frac{dL}{d\phi}\right\Vert^2 $$<h2 id=implicit-regularization-in-stochastic-gradient-descent><a href=#implicit-regularization-in-stochastic-gradient-descent class=header-anchor></a>Implicit Regularization in stochastic gradient descent</h2><p>A similar approach can be applied to stochastic gradient descent, which reads as</p>$$ \tilde{L}(\phi) = L(\phi) + \frac{\alpha}{4|B|}\sum_{i\in B}\left\Vert \frac{dL_{i}}{d\phi}-\frac{dL}{d\phi}\right\Vert^2 $$<p>where $L_{B}$ is the loss on the batch $B$.</p><h1 id=heuristic-methods><a href=#heuristic-methods class=header-anchor></a>Heuristic Methods</h1><h2 id=early-stopping><a href=#early-stopping class=header-anchor></a>Early stopping</h2><p>Early stopping means that we stop the training procedure before the model becomes overfitting. By stopping early, we prevent the model captures the corner features of the training dataset.</p><p>Early stopping has a single hyperparameter, the number of steps after which the training is stopped, this is chosen usually with the help of the validation dataset.</p><h2 id=ensembling><a href=#ensembling class=header-anchor></a>Ensembling</h2><p>Ensembling means we train multiple models on the training dataset, and during the inference time, we take the average inference result of each model. The technique improves the test performance with the sacrifices of training and storing multiple models.</p><p>There are some ensembling methods:</p><ol><li>Use different random initializations. This leads the model reaches different local minimum and may help reduce the overfitting.</li><li>Generate several different datasets by re-sampling the training dataset and train model on each of them.This is also known as <em>bootstrap aggregating</em> or <em>bagging</em>, this division can smooth out the data, since each model tries to predict the distribution of data that is not included in its training dataset.</li></ol><h2 id=dropout><a href=#dropout class=header-anchor></a>Dropout</h2><p>Drop out randomly clamps a subset of hidden units of the layer at each iteration of SGD. This makes the model depends on general feature instead of some specific feature, since the specific feature may be masked.</p><p>At test time, we can run the network as usual with all the hidden units active; however, the network now has more hidden units than it was trained with at any given iteration, so we multiply the weights by one minus the dropout probability to compensate. This is known as the <em>weight scaling inference rule</em>.</p><h2 id=applying-noise><a href=#applying-noise class=header-anchor></a>Applying noise</h2><p>Dropout can be interpreted as applying multiplicative Bernoulli noise to the network activations. We can apply noise to other parts of the model during training.</p><ol><li>We can add noise to the input data, this smooth out the learned function.</li><li>We can also add noise to model parameters, this encourages the model to be robust to small perturbations of the weights.</li><li>We can also perturb the labels. We can change the label of a portion of the training dataset, this can prevent the model from being overconfident.</li></ol><h2 id=bayesian-inference><a href=#bayesian-inference class=header-anchor></a>Bayesian inference</h2><p>The MLE approach tries to find a function $f(\bm{x};\phi)$ that fit the dataset $\{\bm{x}_i,y_i\}$, this approach may be overconfident about the task since the bias of the training data construction.</p><p>To overcome such bias, we treats the parameters $\phi$ as unknown variables instead of scalars. Then we find a distribution over the parameters $\phi$ conditioned on the training data $\{\bm{x}_i,y_i\}$, using <a class=link href=https://en.wikipedia.org/wiki/Bayes%27_theorem target=_blank rel=noopener>Bayesian theorem</a>:</p>$$ \mathrm{Pr}(\phi\mid \{\bm{x}_i,y_i\}) = \frac{\prod_{i}\mathrm{Pr}(y_i\mid \bm{x}_i,\phi)\mathrm{Pr}(\phi)}{\int\prod_{i}\mathrm{Pr}(y_i\mid \bm{x}_i,\phi)\mathrm{Pr}(\phi)d\phi} $$<p>where $\mathrm{Pr}(\phi)$ us the prior probability of the parameters, and the denominator is a normalizing term.</p><p>Then the prediction for unseen item $\{\bm{x},y\}$ is given by the following infinite weighted sum:</p>$$ \mathrm{Pr}(y\mid x, \{\bm{x}_i,y_i\}) = \int \mathrm{Pr}(y\mid \bm{x},\phi)\mathrm{Pr}(\phi\mid \{\bm{x}_i,y_i\})d\phi $$<p>This is an infinite weighted ensemble, where the weights depend on</p><ol><li>the prior probability of the parameters</li><li>the agreement with the data</li></ol><p>Though Bayesian approach is capable of representing the data more robust, it is hard to implement since there is no way to represent an distribution.
Current implementation simplifies the distribution as Gaussian distribution and each parameter is replaced with the mean $\mu$ and standard deviation $\sigma$ of the Gaussian distribution.</p><h2 id=transfer-learning-and-multi-task-learning><a href=#transfer-learning-and-multi-task-learning class=header-anchor></a>Transfer learning and multi-task learning</h2><p>In transfer learning, the model is first pre-trained before training or fine-tuning on the task we are interested in. The idea is that the model may learn some good representation of the data from the main task. Alternatively, we can think transfer learning as initializing the model parameters in a reasonable area such that the minimum is better compared to the random initialization.</p><p>Multi-task learning is a related technique that the model is trained on multiple related tasks concurrently. In this way, the model can learn from multiple datasets and multiple objectives, this encourages the model to learn the essential part of the tasks.</p><h2 id=self-supervised-learning><a href=#self-supervised-learning class=header-anchor></a>Self-supervised learning</h2><p>In some cases, we do not have multiple datasets for pre-training or for multi-tasks. To solve this problem, we can use self-supervised learning to generate large amounts of label-free data. There are two families of self-supervised learning: generative and contrastive.</p><p>In generative self-supervised learning, part of each data example is masked, and the task is to predict the masked part. For example, given a sentence, we can mask the verb and ask for the model to predict the correct verb, the helps the model to learning semantic meaning of a sentence.</p><p>In contrastive self-supervised learning, we try to group related data and separated unrelated data. For example, a cat is more similar to another cat compared with a dog. In this way, the model can learn more robust representations and can be adapted to new tasks easily.</p><h2 id=augmentation><a href=#augmentation class=header-anchor></a>Augmentation</h2><p>Augmentation aims to expand the training dataset, we can perform transformation to each training data without changing the labels, for example we can rotate, flip a image of cat. The augmentation is to teach the model to be invariant to these irrelevant data transformations.</p><h1 id=summary><a href=#summary class=header-anchor></a>Summary</h1><p>To summarize the regularization methods, we use the following picture to depict the mechanisms.
<img src=/p/regularization-methods-in-deep-learning/regularization_overview.png width=1210 height=718 loading=lazy alt="Regularization methods" class=gallery-image data-flex-grow=168 data-flex-basis=404px></p><h1 id=reference><a href=#reference class=header-anchor></a>Reference</h1><ul><li><a class=link href=https://udlbook.github.io/udlbook/ target=_blank rel=noopener>Understanding Deep Learning Chapter 9</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/regularization/>Regularization</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on February 26, 2025 at 11:50 AM</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><script src=https://utteranc.es/client.js repo=MaoSong2022/MaoSong2022.github.io issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Mao Song(毛松)'s Homepage</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>