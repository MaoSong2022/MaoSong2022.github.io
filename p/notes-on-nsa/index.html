<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><link rel=dns-prefetch href=https://fonts.googleapis.com><link rel=dns-prefetch href=https://cdn.jsdelivr.net><link rel=dns-prefetch href=https://scripts.simpleanalyticscdn.com><link rel=preconnect href=https://fonts.googleapis.com crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=preconnect href=https://scripts.simpleanalyticscdn.com crossorigin><meta http-equiv=x-dns-prefetch-control content="on"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5,minimum-scale=1"><meta name=format-detection content="telephone=no"><meta name=theme-color content="#4e54c8" media="(prefers-color-scheme: light)"><meta name=theme-color content="#1a1a2e" media="(prefers-color-scheme: dark)"><link rel=apple-touch-icon href><meta name=description content="DeepSeek 在 25 年 1 月提出了 Natively trainable Sparse Attention (NSA), 一个软硬件结合的稀疏注意力机制，NSA 可以在提高模型推理效率的同时提高计算效率。"><meta name=keywords content><meta name=author content="Mao Song"><link rel=canonical href=https://maosong.website/p/notes-on-nsa/><meta property="og:title" content="Notes on NSA"><meta property="og:description" content="DeepSeek 在 25 年 1 月提出了 Natively trainable Sparse Attention (NSA), 一个软硬件结合的稀疏注意力机制，NSA 可以在提高模型推理效率的同时提高计算效率。"><meta property="og:type" content="article"><meta property="og:url" content="https://maosong.website/p/notes-on-nsa/"><meta property="og:site_name" content="Mao Song(毛松)'s Homepage"><meta property="og:locale" content="en"><meta property="og:image" content="https://maosong.website/p/notes-on-nsa/NSA-architecture.png"><meta property="og:image:alt" content="Notes on NSA"><meta property="article:published_time" content="2025-12-15T17:39:16+08:00"><meta property="article:modified_time" content="2026-01-24T17:06:04+08:00"><meta property="article:author" content="Mao Song"><meta property="article:tag" content="attention"><meta property="article:tag" content="deepseek"><meta property="article:tag" content="best_paper"><meta name=robots content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1"><meta name=googlebot content="index, follow"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"Notes on NSA","description":"DeepSeek 在 25 年 1 月提出了 Natively trainable Sparse Attention (NSA), 一个软硬件结合的稀疏注意力机制，NSA 可以在提高模型推理效率的同时提高计算效率。","author":{"@type":"Person","name":"Mao Song"},"datePublished":"2025-12-15T17:39:16\u002b08:00","dateModified":"2026-01-24T17:06:04\u002b08:00","image":"https:\/\/maosong.website\/p\/notes-on-nsa\/NSA-architecture.png","publisher":{"@type":"Organization","name":"Mao Song(毛松)\u0027s Homepage","logo":{"@type":"ImageObject","url":"https:\/\/maosong.website\/"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/maosong.website\/p\/notes-on-nsa\/"},"keywords":"attention, deepseek, best_paper","articleSection":"post","inLanguage":"en"}</script><title>Notes on NSA</title>
<link rel=stylesheet href=/scss/style.min.fb2ef3860c8335f835ed6d55e46d9c435d7a37375d695eed32deb59ecfadc82b.css><script async src=https://scripts.simpleanalyticscdn.com/latest.js></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><a href=#main-content class=skip-to-main>Skip to main content</a><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu9788782091159651930.jpg width=300 height=240 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Mao Song(毛松)'s Homepage</a></h1><h2 class=site-description>Delving into the Latent Unknown.</h2></div></header><ol class=menu-social><li><a href=https://b23.tv/a0Bb9Z1 target=_blank title=bilibili rel=me><svg role="img" viewBox="0 0 24 24"><title>Bilibili</title><path d="M17.813 4.653h.854c1.51.054 2.769.578 3.773 1.574 1.004.995 1.524 2.249 1.56 3.76v7.36c-.036 1.51-.556 2.769-1.56 3.773s-2.262 1.524-3.773 1.56H5.333c-1.51-.036-2.769-.556-3.773-1.56S.036 18.858.0 17.347v-7.36c.036-1.511.556-2.765 1.56-3.76 1.004-.996 2.262-1.52 3.773-1.574h.774l-1.174-1.12a1.234 1.234.0 01-.373-.906c0-.356.124-.658.373-.907l.027-.027c.267-.249.573-.373.92-.373s.653.124.92.373L9.653 4.44c.071.071.134.142.187.213h4.267a.836.836.0 01.16-.213l2.853-2.747c.267-.249.573-.373.92-.373s.662.151.929.4.391.551.391.907c0 .355-.124.657-.373.906zM5.333 7.24c-.746.018-1.373.276-1.88.773-.506.498-.769 1.13-.786 1.894v7.52c.017.764.28 1.395.786 1.893.507.498 1.134.756 1.88.773h13.334c.746-.017 1.373-.275 1.88-.773.506-.498.769-1.129.786-1.893v-7.52c-.017-.765-.28-1.396-.786-1.894-.507-.497-1.134-.755-1.88-.773zM8 11.107c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c0-.373.129-.689.386-.947.258-.257.574-.386.947-.386zm8 0c.373.0.684.124.933.373.25.249.383.569.4.96v1.173c-.017.391-.15.711-.4.96-.249.25-.56.374-.933.374s-.684-.125-.933-.374c-.25-.249-.383-.569-.4-.96V12.44c.017-.391.15-.711.4-.96.249-.249.56-.373.933-.373z"/></svg></a></li><li><a href=https://github.com/MaoSong2022 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href='https://scholar.google.com/citations?user=BaqGkQQAAAAJ' target=_blank title="Google Scholar" rel=me><svg role="img" viewBox="0 0 24 24"><title>Google Scholar</title><path d="M5.242 13.769.0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977.0-5.548 1.748-6.758 4.269zM12 10a7 7 0 100 14 7 7 0 000-14z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/tags/><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>About</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a></li><li><a href=#method>Method</a><ol><li><a href=#overview>Overview</a></li><li><a href=#design>Design</a><ol><li><a href=#token-compression>Token Compression</a></li><li><a href=#token-selection>Token Selection</a></li><li><a href=#sliding-window>Sliding Window</a></li><li><a href=#kernel-design>Kernel Design</a></li></ol></li></ol></li><li><a href=#experiments>Experiments</a></li><li><a href=#analysis>Analysis</a></li><li><a href=#discussion>Discussion</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main id=main-content class="main full-width" role=main aria-label="Main content"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/llm/>LLM</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/notes-on-nsa/>Notes on NSA</a></h2><h3 class=article-subtitle>DeepSeek 在 25 年 1 月提出了 Natively trainable Sparse Attention (NSA), 一个软硬件结合的稀疏注意力机制，NSA 可以在提高模型推理效率的同时提高计算效率。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>December 15, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>2 minute read</time></div></footer></div></header><section class=article-content><p>DeepSeek 在 25 年 1 月提出了 Natively trainable Sparse Attention (NSA), 一个软硬件结合的稀疏注意力机制，NSA 可以在提高模型推理效率的同时提高计算效率。</p><h2 id=introduction><a href=#introduction class=header-anchor></a>Introduction</h2><p>现有的大模型主要是基于 Transformer 提出的 softmax attention, 其主要问题在于随上下文长度增加，其 latency 也上升更快。理论估计，对于 64k 上下文长度的输出，softmax attention 部分的计算占 $70\%\sim80\%$ 的 latency.</p><p>为了解决 softmax 的 high latency 问题，，一个做法就是使用稀疏注意力机制，如 MInference 等，但是这些系数注意力机制大多没有实际部署，且它们一般只在 inference 阶段使用</p><p>作者认为解决这个问题有两个挑战：</p><ol><li>Hardware-aligned inference speedup: 降低 inference latency 需要算法与硬件结合，不能只关注算法层面的改进</li><li>Training-aware algorithm design: 需要在训练阶段也支持算法，从而可以降低训练的算力消耗并且保持模型的表现</li></ol><p>为了解决这两个问题，作者就提出了 natively trainable sparse attention (NSA) 架构。NSA 通过将 key 和 value 分割为不同的 block, 然后基于三种 path: compressed coarse-grained tokens, selectively retrained fine-grained tokens 以及 sliding windows for local contextual information 来进行处理和过滤。NSA 提出了两点观点改进：</p><ol><li>Hardware-aligned system: 优化了 blockwise sparse attention 来平衡 arithmetic intensity.</li><li>Training-aware design: 支持端到端的训练和部署</li></ol><h2 id=method><a href=#method class=header-anchor></a>Method</h2><h3 id=overview><a href=#overview class=header-anchor></a>Overview</h3><p>作者首先回顾了 attention 的定义如下：</p>$$
\mathbf{o}_t=\mathrm{Attn}(\mathbf{q_t},\mathbf{k}_{:,t}, \mathbf{v}_{:,t})=\sum_{i=1}^t \frac{\alpha_{t,i}}{\sum_{t,i}\alpha_{t,i}}\mathbf{v_i},\ \alpha_{t,i} = \exp\left(\frac{\mathbf{q_t}^T\mathbf{k}_{i}}{\sqrt{d_k}}\right)
$$<p>其中 $\mathbf{q_t}\in\mathbb{R}^{d_k}$.</p><p>接下来是 Arithmetic Intensity. Arithmetic intensity 指的是 FLOPs 与内存访问次数之比。由于现在的 GPU 都是计算密集型设备，理想情况下应该是 Arithmetic intensity 越高越好。</p><p>对于 causal self-attention 来说，在训练以及 prefilling 阶段，由于 batch 较大，因此整体的 Arithmetic intensity 较高，因而这两个阶段是 computer-bound. 但是在 decoding 阶段，由于其 token-by-token generation 的性质，每次生成新的 token 时都需要重新加载 KV cache, 因而是 memory-bound.</p><p>从而我们的优化目标也变得不一致：在训练阶段，我们希望降低计算消耗，而在推理 (decodng) 阶段，我们希望降低内存访问次数。</p><p>基于这两个目标，作者提出了使用 $\mathbf{k}_{:,t}, \mathbf{v}_{:,t}$ 的子集 $\tilde{K}_t, \tilde{V}_t$ 来参与计算，其对应的 attention 如下所示</p>$$
\tilde{K}_t=f_K(\mathbf{q_t},\mathbf{k}_{:,t}, \mathbf{v}_{:,t}), \tilde{V}_t=f_V(\mathbf{q_t},\mathbf{k}_{:,t}, \mathbf{v}_{:,t}), \mathbf{o}_t=\mathrm{Attn}(\mathbf{q_t},\tilde{K}_t, \tilde{V}_t)
$$<p>我们还可以结合不同的方法来进行组合：</p>$$
\mathbf{o}_t^*=\sum_{c\in\mathcal{C}}g_t^c\mathrm{Attn}(\mathbf{q_t},\tilde{K}_t^c, \tilde{V}_t^c)
$$<p>作者在本文中使用了三种方法 $\mathcal{C}=\{\mathrm{cmp},\mathrm{slc},\mathrm{win}\}$, 分别代表了 compression, selection 以及 sliding window, $g_t^c\in[0,1]$ 代表了不同方法对应的 gating score, 类似于 MoE 的 gating layer, $g_t^c$ 由一个 MLP 和一个 sigmoid activation 生成。最终 NSA 的架构如下图所示</p><p><img src=/p/notes-on-nsa/NSA-architecture.png width=1364 height=402 loading=lazy alt="Overview of NSA architecture" class=gallery-image data-flex-grow=339 data-flex-basis=814px></p><p>作者定义 $N_t$ 代表参与计算的 KV 的总个数：</p>$$
N_t = \sum_{c\in\mathcal{C}} \mathrm{size}[\tilde{K}_t^c].
$$<p>作者使用了一个较高的 sparsity ratio 来保证 $N_t<<t$.</p><h3 id=design><a href=#design class=header-anchor></a>Design</h3><p>接下来作者分别介绍了每一部分的设计</p><h4 id=token-compression><a href=#token-compression class=header-anchor></a>Token Compression</h4><p>对于 token compression, 其定义如下：</p>$$
\tilde{K}_t^{\mathrm{cmp}} = f_K^{\mathrm{cmp}}(\mathbf{k}_{:,t})=\left\{\phi(\mathbf{k}_{id+1:id+l})\mid 0\leq i\leq \left\lfloor\frac{t-l}{d}\right\rfloor\right\}\in\mathbb{R}^{d_k\times \left\lfloor\frac{t-l}{d}\right\rfloor}
$$<p>其中 $l$ 是 block size, $d$ 是 sliding stride, $\phi:\mathbb{R}^{l\times d_k}\to \mathbb{R}^d_k$ 是一个 MLP 用于将 block key 映射为一个单一的 key. 对于 $\tilde{V}_t^{\mathrm{cmp}}$ 作者也使用了类似的做法。</p><h4 id=token-selection><a href=#token-selection class=header-anchor></a>Token Selection</h4><p>仅使用 compressed token 的话，可能会丢失一些细粒度的信息。因此，作者额外提出了 token selection 机制来解决这个问题。</p><p>作者使用的做法是 blockwise selection. 这样做的原因有两点：</p><ol><li>hardware efficiency. 这样做的原因是 GPU 访问内存是在 block 层面进行的，因而更加高效</li><li>inherent distribution patterns of attention scores. MInference 证明了 attention score 在空间上存在连续性。即相邻的 key 对应的重要性非常相似</li></ol><p>为了实现 block-wise selection, 作者首先将 key value sequences 分割为 blocks, 然后针对每个 blocks 分配 Importance score.</p><p>作者首先介绍了如何计算不同 block 的 importance score.</p><p>如果 selection block size 与 compression block size ，即 $l'=l$ 相同的话，则我们可以直接用 compression block 提供的信息：</p>$$
\mathbf{p}_{t}^{\mathrm{cmp}} = \mathrm{sotmax}\left(\mathbf{q}_t^T\tilde{K}_t^{\mathrm{cmp}}\right)
$$<p>其中 $\mathbf{p}_{t}^{\mathrm{cmp}}\in\mathbb{R}^{\left\lfloor\frac{t-l}{d}\right\rfloor+1}$ 代表了 $\mathbf{q}_t$ 和 compressed key $\tilde{K}_t^{\mathrm{cmp}}$ 之间的 attention score.</p><p>如果 $l'\neq l$ 的话，作者通过空间关系来进行计算，假设 $l\leq l'$, $d\mid l$, $d\mod l'$, 则我们有</p>$$
\mathbf{p}_{t}^{\mathrm{slc}}[j] = \sum_{m=0}^{l'/d-1}\sum_{n=0}^{l/d-1}\mathbf{p}_{t}^{\mathrm{cmp}}\left[\frac{l'}{d}j-m-n\right]
$$<p>对于 <a class=link href=https://maosong.website/p/notes-on-gqa/ target=_blank rel=noopener>GQA</a> 和 <a class=link href=https://maosong.website/p/notes-on-mqa/ target=_blank rel=noopener>MQA</a>, 由于其 KV-cache 在 heads 之间共享，因此我们必须保证不同 heads 之间的 consistency, 因此作者提出了 shared importance score 如下：</p>$$
\mathbf{p}_{t}^{\mathrm{slc}'} = \sum_{h=1}^H\mathbf{p}_{t}^{\mathrm{slc},(h)}
$$<p>接下来，对于每个 block 及其对应的 Importance score, 作者保存 top-$n$ sparse blcoks, 如下所示</p>$$
\begin{aligned}
\mathcal{I}_t &= \{i\mid \mathrm{rank}(p_t^{\mathrm{slc}'}[i])\leq n\}\\
\tilde{K}_t^{\mathrm{slc}} &= \mathrm{Cat}\left[\{\mathbf{k}_{il'+1:(i+1)l'}\mid i\in \mathcal{I}_t\}\right]
\end{aligned}
$$<p>其中 $\mathrm{rank}(\cdot)$ 代表了降序排列的 importance scores. $\mathcal{I}_t$ 是选择出来的 block indices, $\mathrm{Cat}(\cdot)$ 表示了 concatenation operation. $\tilde{K}_t^{\mathrm{slc}}\in\mathbb{R}^{d_k\times il'}$ 代表了选择出来的 key.</p><h4 id=sliding-window><a href=#sliding-window class=header-anchor></a>Sliding Window</h4><p>为了避免 local pattern 对 compression token 以及 selection token 的学习产生影响，作者额外使用了一个 branch 来学习这个 local pattern. 其具体做法就是维持一个 sliding window 用于最近的若干个 token, 即</p>$$
\tilde{K}_t^{\mathrm{win}} = \mathbf{k}_{t-w:t}, \tilde{V}_t^{\mathrm{win}} = \mathbf{v}_{t-w:t}
$$<p>这里 $w$ 是 window size.</p><p>为了进一步避免 shortcut learning, 对于三个 branch 作者提供了不同的 key 和 values</p><h4 id=kernel-design><a href=#kernel-design class=header-anchor></a>Kernel Design</h4><p>接下来是针对硬件设计进行的优化。由于 flash attention 2 对 compression attention 以及 sliding window attention 已经支持的比较好，作者这里介绍了如何针对 selection attention 进行优化。</p><h2 id=experiments><a href=#experiments class=header-anchor></a>Experiments</h2><p>作者构建了一个 27B-A3B 的 MoE 模型，attention 基于 GQA, MoE 基于 <a class=link href=https://maosong.website/p/notes-on-deepseekmoe/ target=_blank rel=noopener>DeepSeekMoE</a>. 模型配置如下表所示</p><div class=table-wrapper><table><thead><tr><th>field</th><th>value</th></tr></thead><tbody><tr><td>layers</td><td>30</td></tr><tr><td>hidden dimension</td><td>2560</td></tr><tr><td>head groups</td><td>4</td></tr><tr><td>attention heads</td><td>64</td></tr><tr><td>query head dimension</td><td>192</td></tr><tr><td>value head dimension</td><td>128</td></tr><tr><td>routed experts</td><td>72</td></tr><tr><td>shared experts</td><td>2</td></tr><tr><td>activated experts</td><td>6</td></tr><tr><td>dense layers</td><td>1</td></tr></tbody></table></div><p>NSA 配置如下</p><div class=table-wrapper><table><thead><tr><th>field</th><th>value</th></tr></thead><tbody><tr><td>$l$</td><td>32</td></tr><tr><td>$d$</td><td>16</td></tr><tr><td>$l'$</td><td>64</td></tr><tr><td>$n$</td><td>16</td></tr><tr><td>$w$</td><td>512</td></tr></tbody></table></div><p>其中 selection blocks 包含初始的一个 block 以及最近的 2 个 block.</p><p>模型先在 8K 的上下文长度下使用 270B token 进行预训练，接下来在使用 <a class=link href=https://maosong.website/p/notes-on-yarn/ target=_blank rel=noopener>YARN</a> 将模型上下文通过 continual pre-training 以及 SFT 扩展到 32K. 训练过程的损失如下图所示</p><p><img src=/p/notes-on-nsa/NSA-training-loss.png width=1073 height=780 loading=lazy alt="Training loss of NSA" class=gallery-image data-flex-grow=137 data-flex-basis=330px></p><p>作者从 general performance, long-context performance 以及 CoT reasoning performance 三个层面来评估 NSA 的表现。</p><p>首先是 NSA 与其他 sparse attention 以及 baseline 在通用任务上表现的对比，结果如下图所示</p><p><img src=/p/notes-on-nsa/NSA-general-performance.png width=1355 height=181 loading=lazy alt="Performance of NSA on general benchmarks" class=gallery-image data-flex-grow=748 data-flex-basis=1796px></p><p>接下来是 NSA 在 LongBench 上的表现：</p><p><img src=/p/notes-on-nsa/NSA-long-context-performance.png width=1361 height=358 loading=lazy alt="Performance of NSA on LongBench" class=gallery-image data-flex-grow=380 data-flex-basis=912px></p><p>作者还使用了 <a class=link href=https://maosong.website/p/notes-on-deepseek-r1/ target=_blank rel=noopener>DeepSeek-R1</a> 中的知识蒸馏方法，结果如下表所示</p><div class=table-wrapper><table><thead><tr><th>Generation token limit</th><th>8192</th><th>16384</th></tr></thead><tbody><tr><td>Full Attention-R</td><td>0.046</td><td>0.092</td></tr><tr><td>NSA-R</td><td>0.121</td><td>0.146</td></tr></tbody></table></div><p>上面的结果均验证了 NSA 的有效性</p><h2 id=analysis><a href=#analysis class=header-anchor></a>Analysis</h2><p>接下来，作者分析了 NSA 的性质。作者首先对比了 NSA 和 flash attention 2 的训练速度，结果如下图所示</p><p><img src=/p/notes-on-nsa/NSA-training-speed-performance.png width=883 height=514 loading=lazy alt="Performance comparison between NSA and flash attention 2" class=gallery-image data-flex-grow=171 data-flex-basis=412px></p><p>可以看到，相比于 flash attention 2, NSA 在 forward 过程和 backward 过程的的效率分别提升了 9 倍和 6 倍。作者认为这是由于两个优点：</p><ol><li>NSA 使用了 block-wise memory access, 提高了 tensor core 的利用率</li><li>loop scheduling 减少了 KV transfer 时的 kernel 冗余</li></ol><p>作者还对比了不同 attention 的解码速度，在 NSA 中，每次只需要 $\left\lfloor\frac{s-l}{d}\right\rfloor+nl'+w$ 个 token 就可以完成计算，作者对比不同 attention 所需余姚的 token 如下表所示如下表所示</p><div class=table-wrapper><table><thead><tr><th>Context Length</th><th>8192</th><th>16384</th><th>32768</th><th>65536</th></tr></thead><tbody><tr><td>Full attention</td><td>8192</td><td>16384</td><td>32768</td><td>65536</td></tr><tr><td>NSA</td><td>2048</td><td>2560</td><td>3584</td><td>5632</td></tr><tr><td>speedup</td><td>4x</td><td>6.4x</td><td>9.1x</td><td>11.6x</td></tr></tbody></table></div><h2 id=discussion><a href=#discussion class=header-anchor></a>Discussion</h2><h2 id=conclusion><a href=#conclusion class=header-anchor></a>Conclusion</h2><p>作者在本文中提出了 NSA, 一个通过软硬件协同结合 compression, selection 以及 sliding window 的稀疏注意力机制，作者通过实验验证了其有效性。</p><h2 id=references><a href=#references class=header-anchor></a>References</h2><ul><li><a class=link href=http://arxiv.org/abs/2502.11089 target=_blank rel=noopener>arxiv</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/attention/>Attention</a>
<a href=/tags/deepseek/>Deepseek</a>
<a href=/tags/best_paper/>Best_paper</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on January 24, 2026 at 5:06 PM</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/notes-on-deepseek-v3.2/><div class=article-details><h2 class=article-title>Notes on DeepSeek-V3.2</h2></div></a></article><article><a href=/p/notes-on-mla/><div class=article-details><h2 class=article-title>Notes on MLA</h2></div></a></article><article><a href=/p/notes-on-gated-attention/><div class=article-details><h2 class=article-title>Notes on Gated Attention</h2></div></a></article><article><a href=/p/notes-on-minimax-01/><div class=article-details><h2 class=article-title>Notes on MiniMax-01</h2></div></a></article><article><a href=/p/notes-on-deepseek-v3/><div class=article-details><h2 class=article-title>Notes on DeepSeek-V3</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=MaoSong2022/MaoSong2022.github.io issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2026 Mao Song(毛松)'s Homepage</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>