<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Report on Mao Song(毛松)'s Homepage</title><link>https://maosong.website/tags/report/</link><description>Recent content in Report on Mao Song(毛松)'s Homepage</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 17 Jan 2026 17:19:57 +0800</lastBuildDate><atom:link href="https://maosong.website/tags/report/index.xml" rel="self" type="application/rss+xml"/><item><title>State of AI--从OpenRouter 100T token使用情况了解AI 大模型能力分层竞争逻辑</title><link>https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/</link><pubDate>Sat, 17 Jan 2026 17:04:07 +0800</pubDate><guid>https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/</guid><description>&lt;h2 id="介绍">&lt;a href="#%e4%bb%8b%e7%bb%8d" class="header-anchor">&lt;/a>介绍
&lt;/h2>&lt;p>本报告基于 OpenRouter 2024 年 11 月 - 2025 年 11 月 100T token 调用数据，从模型、任务、用户维度分析 AI 大模型使用特征，核心结论如下：&lt;/p>
&lt;p>&lt;strong>模型维度&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>市场格局&lt;/strong>：闭源模型占 70% token 使用量，主导高价值、高稳定性场景；开源模型占 30%，聚焦低成本、场景化需求，其中中国开源模型占比持续上升，但开源市场因竞争呈现碎片化（2025 年底无单一开源模型占比超 25%）。&lt;/li>
&lt;li>&lt;strong>模型偏好&lt;/strong>：不同闭源模型形成差异化优势（Anthropic 擅长复杂推理 / 代码、Google 偏向通用翻译 / 知识问答、xAI/Qwen 专注编程等）。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>任务维度&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>核心需求&lt;/strong>：编程类任务 token 占比超 50%，Anthropic 占该领域 60% 以上份额，且编程任务输入长度是其他类别 3 倍以上；但 90% 编程需求依赖闭源模型，开源模型存在能力短板。&lt;/li>
&lt;li>&lt;strong>场景特征&lt;/strong>：角色扮演是开源模型第一大任务（占比超 50%），其在该场景 token 占比（43%）接近闭源模型（42%）且持续上升；agentic inference（工具调用推理）场景 token 占比超 60%，Claude 系列主导该领域。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>用户维度&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>核心逻辑&lt;/strong>：能力优于成本，企业愿为强能力模型支付溢价（价格弹性低，降价 10% 仅带来 0.5~0.7% 使用率增长）；免费开源模型仅达 “可用” 水平，因无法落地到实际工作流程难以形成竞争力；小模型数量占比下降，反映市场对模型能力要求提升。&lt;/li>
&lt;li>&lt;strong>留存逻辑（水晶鞋效应）&lt;/strong>：用户留存由 “能力拐点”（首次解决未被满足的长尾需求）驱动，如 Gemini 2.5 Pro、Claude 4 Sonnet 实现能力突破后 5 个月留存率仍达 40%；缺乏能力突破的模型留存率极差，且 “水晶鞋时刻” 窗口狭窄。&lt;/li>
&lt;/ol>
&lt;h2 id="background">&lt;a href="#background" class="header-anchor">&lt;/a>Background
&lt;/h2>&lt;p>分析使用的 100T token 基于 OpenRouter 从&lt;strong>2024 年 11 月到 2025 年 11 月&lt;/strong>的模型使用情况。&lt;/p>
&lt;p>对于模型，作者将模型分为三类， 分别是 Proprietary, Chinese Open Sourced (Chinese OSS), Rest-of-World (RoW) open source models&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>category&lt;/th>
&lt;th>examples&lt;/th>
&lt;th>description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Proprietary&lt;/td>
&lt;td>Claude, GPT-5&lt;/td>
&lt;td>闭源商业模型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Chinese OSS&lt;/td>
&lt;td>DeepSeek-V3, Qwen&lt;/td>
&lt;td>中文开源模型&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RoW OSS&lt;/td>
&lt;td>mistral, LLaMA&lt;/td>
&lt;td>其他国家开源模型&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>作者基于 metadata 和 GoogleTagClassifier 将任务分为以下类别&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>category&lt;/th>
&lt;th>sub-category&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Programming&lt;/td>
&lt;td>- Computers &amp;amp; Electronics&lt;br>- Programming&lt;br>- Science&lt;br>- Computer Science&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Roleplay&lt;/td>
&lt;td>- Games&lt;br>- Roleplaying Games&lt;br>- Adult&lt;br>- Arts &amp;amp; Entertainment&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Translation&lt;/td>
&lt;td>- Reference&lt;br>- Language Resources&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>General Q&amp;amp;A / Knowledge&lt;/td>
&lt;td>- Reference&lt;br>- General Reference&lt;br>- News&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Productivity/Writing&lt;/td>
&lt;td>- Computers &amp;amp; Electronics&lt;br>- Software&lt;br>- Business &amp;amp; Productivity Software&lt;br>- Business &amp;amp; Industrial&lt;br>- Business Services&lt;br>- Writing &amp;amp; Editing Services&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Education&lt;/td>
&lt;td>- Jobs &amp;amp; Education&lt;br>- Education&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Literature/Creative Writing&lt;/td>
&lt;td>- Books &amp;amp; Literature&lt;br>- narrative leaves under &lt;br>- Arts &amp;amp; Entertainment&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="model">&lt;a href="#model" class="header-anchor">&lt;/a>Model
&lt;/h2>&lt;p>首先是开源模型与闭源模型的对比，结果如下图所示&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-open-vs-closed.png"
width="1358"
height="654"
loading="lazy"
alt="Open v.s. Closed source model split"
class="gallery-image"
data-flex-grow="207"
data-flex-basis="498px"
>&lt;/p>
&lt;p>结果显示，开源模型的 token 占比在 $30\%$ 左右，并且中文开源模型 token 占比在持续上升。作者分析认为，闭源模型有着更好的表现以及稳定性，而开源模型的透明程度，成本控制以及可定制化更好。&lt;/p>
&lt;p>在闭源模型中，作者对比了不同模型在不同任务上的使用情况，得出了模型偏好如下表所示&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Provider&lt;/th>
&lt;th>preference&lt;/th>
&lt;th>description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Anthropic&lt;/td>
&lt;td>- Programming&lt;br>- Technology&lt;/td>
&lt;td>擅长推理，代码，复杂任务，领域专家&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Google&lt;/td>
&lt;td>- Translation&lt;br>- Science&lt;br>- Technology&lt;br>- General Knowledge&lt;/td>
&lt;td>各个任务都没有短板，通用信息引擎&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>xAI&lt;/td>
&lt;td>programming&lt;/td>
&lt;td>专注编程，程序员专用&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenAI&lt;/td>
&lt;td>- Science&lt;br>- Programming&lt;br>- Technology&lt;/td>
&lt;td>介于 Anthropic 和 Google 之间，更人性化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DeepSeek&lt;/td>
&lt;td>- roleplay&lt;/td>
&lt;td>日常对话，面向消费端&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Qwen&lt;/td>
&lt;td>- programming&lt;/td>
&lt;td>专注编程，适用范围比 Anthropic 广&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>在开源模型中，DeepSeek 占了 $42.51\%$，模型 token 使用情况对比如下表所示&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Provider&lt;/th>
&lt;th># Tokens (T)&lt;/th>
&lt;th>ratio (%)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>DeepSeek&lt;/td>
&lt;td>14.37&lt;/td>
&lt;td>42.51&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Qwen&lt;/td>
&lt;td>5.59&lt;/td>
&lt;td>16.54&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Meta LLaMA&lt;/td>
&lt;td>3.96&lt;/td>
&lt;td>11.72&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Mistral AI&lt;/td>
&lt;td>2.92&lt;/td>
&lt;td>8.64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenAI&lt;/td>
&lt;td>1.65&lt;/td>
&lt;td>4.88&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Minimax&lt;/td>
&lt;td>1.26&lt;/td>
&lt;td>3.73&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Z-AI&lt;/td>
&lt;td>1.18&lt;/td>
&lt;td>3.49&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TNGTech&lt;/td>
&lt;td>1.13&lt;/td>
&lt;td>3.34&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MoonshotAI&lt;/td>
&lt;td>0.92&lt;/td>
&lt;td>2.72&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Google&lt;/td>
&lt;td>0.82&lt;/td>
&lt;td>2.43&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>但是到 25 年底，因为竞争太强，已经不存在单一模型占比超过 $25\%$, 下面是开源模型 token 使用随时间变化情况&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-token-usage-over-time.png"
width="1352"
height="516"
loading="lazy"
alt="Token usage of OSS model over time"
class="gallery-image"
data-flex-grow="262"
data-flex-basis="628px"
>&lt;/p>
&lt;p>接下来，作者将模型分为 Large (&amp;gt; 70B), Medium (&amp;gt; 15B, &amp;lt; 70B) 以及 Small (&amp;lt; 15B) 三个区间，分析了各自的使用情况。结果发现，整体趋势为，Small 区间的模型数量占比正在减少，如下图所示&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-num-oss-models.png"
width="1350"
height="529"
loading="lazy"
alt="evolution of the number of OSS models"
class="gallery-image"
data-flex-grow="255"
data-flex-basis="612px"
>&lt;/p>
&lt;p>token 使用这方面，由于小模型本地部署较多，因此报告结果存在一定偏差性。&lt;/p>
&lt;p>作者还对比了不同模型的价格与 token 使用情况，作者根据中位数 $0.73\$$ per 1M tokens 来将模型分为了四类：&lt;/p>
&lt;ol>
&lt;li>Premium Workloads (high-cost, high-usage): technology, science 等任务&lt;/li>
&lt;li>Mass-Market Volum Drivers (low-cost, high-usage): programming, roleplay 等任务&lt;/li>
&lt;li>Specialized Experts (high-cost, low-usage): finance, academia, health 等任务&lt;/li>
&lt;li>Niche Utilities (low-cost, low-usage): translation, legal 等任务&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-classification-models.png"
width="1493"
height="875"
loading="lazy"
alt="model landscape: cost v.s. usage"
class="gallery-image"
data-flex-grow="170"
data-flex-basis="409px"
>&lt;/p>
&lt;p>图中红线是拟合出来的结果，红线说明，降低 $10\%$ 的价格只会带来 $0.5\sim0.7\%$ 的 token 使用率增长。上面这幅图说明了闭源模型主要解决高价值的任务，而开原模型则是解决 low-cost 的任务&lt;/p>
&lt;p>作者对比不同模型，给出了一些例子，如下表所示&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-example-models.png"
width="1550"
height="890"
loading="lazy"
alt="Example models by segment"
class="gallery-image"
data-flex-grow="174"
data-flex-basis="417px"
>&lt;/p>
&lt;p>这里的关键结论有几点：&lt;/p>
&lt;ol>
&lt;li>宏观需求无弹性，微观行为分化：企业愿意支付成本使用更强模型，而个人用户则对成本比较敏感&lt;/li>
&lt;li>Jevons Paradox: 模型成本下降之后，使用率反而会上升&lt;/li>
&lt;li>&lt;strong>能力优于成本&lt;/strong>：用户愿意为更强的模型付出更高的成本&lt;/li>
&lt;li>低价不能成为竞争力：免费开源模型不能落地的原因是仅仅达到“可用”水平，无法部署到实际工作流程中&lt;/li>
&lt;/ol>
&lt;h2 id="task">&lt;a href="#task" class="header-anchor">&lt;/a>Task
&lt;/h2>&lt;p>首先是所有模型在不同任务上的 token 使用情况，可以看到，programming 的占比最近已经升到了 $50\%$ 以上&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-category-close-model.png"
width="1353"
height="509"
loading="lazy"
alt="Category trend of tokens"
class="gallery-image"
data-flex-grow="265"
data-flex-basis="637px"
>&lt;/p>
&lt;p>并且对于 programming, Anthropic 拥有 $60\%$ 以上的份额，如下表所示&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-anthropic-share-progamming.png"
width="1349"
height="535"
loading="lazy"
alt="Share of models on programming"
class="gallery-image"
data-flex-grow="252"
data-flex-basis="605px"
>&lt;/p>
&lt;p>接下来是开源模型在不同任务上的 token 使用情况。&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-category-usage.png"
width="1348"
height="577"
loading="lazy"
alt="Category Trends of OSS models over time"
class="gallery-image"
data-flex-grow="233"
data-flex-basis="560px"
>&lt;/p>
&lt;p>排名前二的任务分别为 roleplay 以及 programming, 前者占比 $50\%$ 以上， 而后者占比在 $15\sim20\%$ 。中文的 OSS model 主要也集中在这两个任务上，但是 roleplay 占比下降到了 $33\%$. 而 programming+technology 的占比为 $39\%$.&lt;/p>
&lt;p>对于 programming，目前 $90\%$ 的 token 都基于闭源商业模型，对于开源模型，目前中文开源模型的占比已经超过了其他开源模型&lt;/p>
&lt;p>对于 roleplay, 其他开源模型与闭源商业模型的占比分别为 $43\%$, $42\%$ , 且开源模型占比持续上升&lt;/p>
&lt;p>开源模型的几个关键用途为：&lt;/p>
&lt;ol>
&lt;li>roleplay and creative dialogue: 写作，虚拟人物等&lt;/li>
&lt;li>programming: 编程，开发&lt;/li>
&lt;li>translation: 多语种任务&lt;/li>
&lt;li>general QA: 日常问答&lt;/li>
&lt;/ol>
&lt;p>作者还对 token 长度进行了分析，结果显示，目前输入长度区间为 $[1.5K, 6K]$, 输出长度区间为 $[150, 400]$, 这说明不同于早期简单问答，现在用户倾向于输入更丰富的上下文或者材料来让模型解决相应问题。而且，&lt;strong>programming 相关的输入长度大约是其他 category 输入的 3 倍以上&lt;/strong>，下图是不同 category 输入长度随时间的变化情况&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-prompt-token-length.png"
width="1355"
height="512"
loading="lazy"
alt="Length of prompt token length trends"
class="gallery-image"
data-flex-grow="264"
data-flex-basis="635px"
>&lt;/p>
&lt;p>作者还展示了不同子任务的占比情况（只列出大于 $10\%$ 的部分）&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>category&lt;/th>
&lt;th>sub-category&lt;/th>
&lt;th>ratio (%)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Roleplay&lt;/td>
&lt;td>Games/Roleplaying Games&lt;/td>
&lt;td>57.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>Books &amp;amp; Literature/Wrters Resources&lt;/td>
&lt;td>16.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>Adult&lt;/td>
&lt;td>15.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Programming&lt;/td>
&lt;td>general programming&lt;/td>
&lt;td>66.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>developing tools&lt;/td>
&lt;td>26.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Translation&lt;/td>
&lt;td>general&lt;/td>
&lt;td>51&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>Foreign Language Resources&lt;/td>
&lt;td>49&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Science&lt;/td>
&lt;td>Machine Learning &amp;amp; AI&lt;/td>
&lt;td>80.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Technology&lt;/td>
&lt;td>personal assistences&lt;/td>
&lt;td>31.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>software&lt;/td>
&lt;td>10.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>health&lt;/td>
&lt;td>general&lt;/td>
&lt;td>25.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>research&lt;/td>
&lt;td>11.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>finance&lt;/td>
&lt;td>currencies&lt;/td>
&lt;td>19.2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>stocks&lt;/td>
&lt;td>15.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>investing&lt;/td>
&lt;td>15.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>accounting&lt;/td>
&lt;td>13.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>academia&lt;/td>
&lt;td>educational&lt;/td>
&lt;td>42.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>writing&lt;/td>
&lt;td>36.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>management&lt;/td>
&lt;td>14.8&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>legal&lt;/td>
&lt;td>Government&lt;/td>
&lt;td>42.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>Legal&lt;/td>
&lt;td>18.9&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>trivia&lt;/td>
&lt;td>-&lt;/td>
&lt;td>96.2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>marketing&lt;/td>
&lt;td>marketing&lt;/td>
&lt;td>66.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>sales&lt;/td>
&lt;td>16.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>seo&lt;/td>
&lt;td>seo&lt;/td>
&lt;td>100&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>接下来是模型在 agentic inference 场景下的 token 使用情况，从下图可以看出，Reasoning token 占比已经超过了 $60\%$. 这代表了用户对于使用工具解决复杂能力的需求&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-reasoning-token.png"
width="1361"
height="507"
loading="lazy"
alt="Reasoning token Trend over time"
class="gallery-image"
data-flex-grow="268"
data-flex-basis="644px"
>&lt;/p>
&lt;p>这 agentic inference 场景下, 使用最多的模型有 Grok Code Fast1, Gemini 2.5 Pro/flash 等，下图是不同模型的占比情况&lt;/p>
&lt;p>&lt;img src="https://maosong.website/p/state-of-ai--%E4%BB%8Eopenrouter-100t-token%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E4%BA%86%E8%A7%A3ai-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E5%88%86%E5%B1%82%E7%AB%9E%E4%BA%89%E9%80%BB%E8%BE%91/State-AI-tool-use-trend.png"
width="1351"
height="525"
loading="lazy"
alt="tool-use calls trend"
class="gallery-image"
data-flex-grow="257"
data-flex-basis="617px"
>&lt;/p>
&lt;p>可以看到，Claude 系列占了大部分份额&lt;/p>
&lt;h2 id="user">&lt;a href="#user" class="header-anchor">&lt;/a>User
&lt;/h2>&lt;p>用户这方面，中国和北美的使用占了近 $80\%$, 其中中文用户最近占 $31\%$&lt;/p>
&lt;p>语言上，token 的语言占比情况如下表所示&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Language&lt;/th>
&lt;th>Token Share (%)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>English&lt;/td>
&lt;td>82.87&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Chinese (Simplified)&lt;/td>
&lt;td>4.95&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Russian&lt;/td>
&lt;td>2.47&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Spanish&lt;/td>
&lt;td>1.43&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Thai&lt;/td>
&lt;td>1.03&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Other (combined)&lt;/td>
&lt;td>7.25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>作者还分了用户留存行为，发现一小部分用户的留存率非常高，作者将这个现象称之为水晶鞋效应 (Glass Slipper effect). 作者分析原因有以下几点：&lt;/p>
&lt;ol>
&lt;li>市场存在未被满足的需求：尽管 AI 模型层出不穷，但是始终有些任务连续多代模型都无法解决，也就是 &amp;quot; 水晶鞋“”&lt;/li>
&lt;li>新模型发布是一个“试穿水晶鞋的过程”：每一代模型都会被用于测试是否能解决这些未解决需求&lt;/li>
&lt;li>“灰姑娘时刻”：一旦某一个模型解决这个未解决的需求，这个模型就会吸引相当一部分用户从维持比较高的留存率&lt;/li>
&lt;/ol>
&lt;p>作者举例说明，Gemini 2.5 Pro 和 Claude 4 Sonnet 在 5 个月以后用户留存率还有 $40\%$, 而 Gemini 2.0 Flash 和 LLaMA 4 Maverick 的用户留存率非常差。作者因此得出三个关键结论：&lt;/p>
&lt;ol>
&lt;li>首次解决是持久竞争的核心优势：也就是先发制人&lt;/li>
&lt;li>用户留存率是能力拐点的信号：因为模型实现了从不可能到可能得跨越，才能保留一批早期用户&lt;/li>
&lt;li>“水晶鞋时刻”的窗口很窄：一旦抓不住机会，很可能就会丢掉一大批用户群体&lt;/li>
&lt;/ol>
&lt;h2 id="references">&lt;a href="#references" class="header-anchor">&lt;/a>References
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://openrouter.ai/state-of-ai" target="_blank" rel="noopener"
>state of AI&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>